#Training configuration file
exp_name: "singing_voice_44k_6s" #name of the experiment

model_dir: None #directory where the model will be saved locally

trainer:
  _target_: "training.trainer.Trainer"

  #main options
#related to optimization
optimizer:
  _target_: "torch.optim.AdamW"
  weight_decay: 0.01
  lr: 2e-5 #            help='Learning rate',
  betas: [0.9, 0.999]
  eps: 1e-8 #for numerical stability, we may need to modify it if usinf fp16
  
# Training related.
batch_size: 4 

# Performance-related.
num_workers: 4  #

# I/O-related. moved to logging
seed: 1 # random seed

resume: True
resume_checkpoint: Null

#audio data related
sample_rate: 44100
audio_len: 262144

#training
use_cqt_DC_correction: False #if True, the loss will be corrected for the DC component and the nyquist frequency. This is important because we are discarding the DC component and the nyquist frequency in the cqt

ema_rate: 0.9999  #unused
ema_rampup: 10000  #linear rampup to ema_rate   #help='EMA half-life' 

#gradient clipping
use_grad_clip: True
max_grad_norm: 1

restore : False
checkpoint_id: None

augmentations:
  list: ["segment_length", "gain", "polarity"]
  polarity:
    prob: 0.5
  rms:
    mean: 0.06
    std: 0.002
  segment_length:
    set: [16384, 32768, 65536, 131072, 262144]


