#Training configuration file
exp_name: "VCTK_16k_4s" #name of the experiment

model_dir: None #directory where the model will be saved locally

trainer:
  _target_: "training.trainer.Trainer"

#related to optimization
optimizer:
  _target_: "torch.optim.AdamW"
  weight_decay: 0.01
  lr: 2e-5
  betas: [0.9, 0.999]
  eps: 1e-8 #for numerical stability, we may need to modify it if usinf fp16
  

# Training related.
batch_size: 8 #         help='Total batch size'

# Performance-related.
num_workers: 4

# I/O-related. moved to logging
seed: 1 # random seed

resume: True
resume_checkpoint: Null

#audio data related
sample_rate: 16000
audio_len: 65536

#training
use_cqt_DC_correction: False
#if True, the loss will be corrected for the DC component and the nyquist frequency.
#This is important because we are discarding the DC component and the nyquist frequency in the cqt

ema_rate: 0.9999  #unused
ema_rampup: 10000  #linear rampup to ema_rate

#gradient clipping
use_grad_clip: True
max_grad_norm: 1

restore : False
checkpoint_id: None

augmentations:
  list: ["segment_length", "gain", "polarity"]
  polarity:
    prob: 0.5
  rms:
    mean: 0.05
    std: 0.01
  segment_length:
    set: [16384, 32768, 65536]
    uniform: False


