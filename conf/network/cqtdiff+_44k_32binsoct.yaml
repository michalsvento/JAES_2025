#network from the paper: Solving audio inverse problems with a diffusion model
_target_: "networks.unet_octCQT.Unet_octCQT"

use_norm: True
#filter_out_cqt_DC_Nyq: True
depth: 8 #total depth of the network (including the first stage)
emb_dim: 256 #dimensionality of the RFF embeddings

#dimensions of the first stage (the length of this vector should be equal to num_octs)
Ns: [32,32, 64 ,64, 128, 128,256, 256] #it is hardcoded
#Ns: [8, 8 ,8, 8, 16,16, 16] #it is hardcoded

#attention_layers: [0, 0, 0, 0, 1, 1, 1, 1] #num_octs+bottleneck
attention_layers: [0, 0, 0, 0, 0, 0, 0, 0] #num_octs+bottleneck
checkpointing: [True, True, True, True, True, True, True, True]

#Ns: [8,8,16,16,32,32,64] 
Ss: [2,2,2,2, 2, 2, 2, 2] #downsample factors at the first stage, now it is ignored

num_dils: [1,3,4,5,5,6,6,7]
sample_rate: 44100
audio_len: 262144
cqt:
    window: "kaiser"
    beta: 1
    num_octs: 8
    bins_per_oct: 32 #this needs to be lower than 64, otherwise the time attention is inpractical

bottleneck_type: "res_dil_convs"

num_bottleneck_layers: 1

attention_dict:
    num_heads: 8
    attn_dropout: 0.0
    bias_qkv: False
    N: 0
    rel_pos_num_buckets: 32
    rel_pos_max_distance: 64
    use_rel_pos: True
    Nproj: 8
